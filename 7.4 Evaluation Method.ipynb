{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants and imports.\n",
    "\n",
    "RANDOM_STATE = None\n",
    "BASE_NUM = 1\n",
    "CV = 5\n",
    "TEST_SIZE = 0.2\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, Imputer\n",
    "\n",
    "from msc_preprocessing import CourseOfStudyNamer, CategoricalEncoder, DataFrameSelector\n",
    "from msc_preprocessing import ElementaryNameFixer, ElementarySchoolDistance\n",
    "from msc_preprocessing import NationalitySelector\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data.\n",
    "\n",
    "data = pd.read_csv(os.path.join('datasets', 'base_{}.csv'.format(BASE_NUM)), sep=';')\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.hist(bins=50, figsize=(20,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train / test\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=TEST_SIZE, random_state=RANDOM_STATE)\n",
    "for train_index, test_index in split.split(data, data['DROPPED_OUT']):\n",
    "    train_set = data.loc[train_index]\n",
    "    test_set = data.loc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify that the training set has an equal split of students that dropped out and graduated.\n",
    "\n",
    "train_set['DROPPED_OUT'].value_counts() / len(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify that the testing set has an equal split of students that dropped out and graduated.\n",
    "\n",
    "test_set['DROPPED_OUT'].value_counts() / len(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print correlation from numerical attributes to dropout.\n",
    "\n",
    "corr_matrix = train_set.corr()\n",
    "\n",
    "corr_matrix[\"DROPPED_OUT\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the training set to 'data' for convenience.\n",
    "\n",
    "data = train_set.drop(\"DROPPED_OUT\", axis=1) # drop labels for training set\n",
    "data_labels = train_set[\"DROPPED_OUT\"].copy()\n",
    "\n",
    "test_data = test_set.drop(\"DROPPED_OUT\", axis=1) # drop labels for testing set\n",
    "test_labels = test_set[\"DROPPED_OUT\"].copy()\n",
    "\n",
    "# Pipeline for standard scaling and translating categories to numbers.\n",
    "\n",
    "# Define categorical attributes that need to be translated to numbers.\n",
    "cat_attribs = ['COURSE_OF_STUDY', 'SCHOOL', 'NATIONALITY', ]\n",
    "\n",
    "# Define numerical attributes, data that has numbers.\n",
    "num_attribs = list(data.drop(cat_attribs + ['ELEMENTARY_SCHOOL'], axis=1)) + ['ELEMENTARY_SCHOOL_DISTANCE']\n",
    "\n",
    "# A pipeline for numerical attributes.\n",
    "num_pipeline = Pipeline([\n",
    "        ('elementary_school_fix_names', ElementaryNameFixer()),\n",
    "        ('elementary_school_distance', ElementarySchoolDistance()),\n",
    "        ('selector', DataFrameSelector(num_attribs)), # Select only data that has numbers.\n",
    "        ('imputer', Imputer(strategy=\"median\")), # Replace NULL values with averages.\n",
    "        ('std_scaler', RobustScaler()), # Scale all numerical values to the same scale.\n",
    "    ])\n",
    "\n",
    "# A pipeline for categorial attributes.\n",
    "cat_pipeline = Pipeline([\n",
    "        ('course_of_study_fix_names', CourseOfStudyNamer()),\n",
    "        ('nationality_selector', NationalitySelector()),\n",
    "        ('selector', DataFrameSelector(cat_attribs)), # Select only data that has categories.\n",
    "        ('cat_encoder', CategoricalEncoder(encoding=\"onehot-dense\", handle_unknown='ignore')), # Translate categories to numbers.\n",
    "    ])\n",
    "\n",
    "# Merge the numerical and categorical pipelines.\n",
    "full_pipeline = FeatureUnion(transformer_list=[\n",
    "        (\"num_pipeline\", num_pipeline),\n",
    "        (\"cat_pipeline\", cat_pipeline),\n",
    "    ])\n",
    "\n",
    "# Fit and transform the data for training.\n",
    "data_prepared = full_pipeline.fit_transform(data)\n",
    "data_prepared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate classifiers\n",
    "\n",
    "# A list of the classifiers to evaluate.\n",
    "other_cls_list = [\n",
    "    RandomForestClassifier(random_state=RANDOM_STATE, n_jobs=-1), # With no parameter tuning.\n",
    "    AdaBoostClassifier(random_state=RANDOM_STATE),\n",
    "    GradientBoostingClassifier(random_state=RANDOM_STATE),\n",
    "    LogisticRegression(random_state=RANDOM_STATE),\n",
    "    SVC(),\n",
    "    LinearSVC(),\n",
    "    NuSVC(),\n",
    "    DecisionTreeClassifier(),\n",
    "    KNeighborsClassifier(),\n",
    "    SGDClassifier(random_state=RANDOM_STATE, n_jobs=-1, max_iter=5, tol=None),\n",
    "    SGDClassifier(random_state=RANDOM_STATE, n_jobs=-1, max_iter=1000, tol=1e-3),\n",
    "    GaussianNB(),\n",
    "    LinearDiscriminantAnalysis(),\n",
    "    QuadraticDiscriminantAnalysis(),\n",
    "]\n",
    "\n",
    "# Objects to store cross validated scores.\n",
    "accuracy_scores = np.zeros(len(other_cls_list))\n",
    "f1_scores = np.zeros(len(other_cls_list))\n",
    "precision_scores = np.zeros(len(other_cls_list))\n",
    "recall_scores = np.zeros(len(other_cls_list))\n",
    "roc_scores = np.zeros(len(other_cls_list))\n",
    "\n",
    "# Objects to store test data scores.\n",
    "split_accuracy_scores = np.zeros(len(other_cls_list))\n",
    "split_f1_scores = np.zeros(len(other_cls_list))\n",
    "split_precision_scores = np.zeros(len(other_cls_list))\n",
    "split_recall_scores = np.zeros(len(other_cls_list))\n",
    "split_roc_scores = np.zeros(len(other_cls_list))\n",
    "\n",
    "for idx, other_cls in enumerate(other_cls_list):\n",
    "    print (idx, other_cls)\n",
    "    \n",
    "    other_cls.fit(data_prepared, data_labels)\n",
    "\n",
    "    # Predict using cross validation.\n",
    "    y_train_pred_binary_other = cross_val_predict(other_cls, data_prepared, data_labels, cv=CV, method='predict')\n",
    "\n",
    "    # Record cross validated scores.\n",
    "    accuracy_scores[idx] = accuracy_score(data_labels, y_train_pred_binary_other)\n",
    "    f1_scores[idx] = f1_score(data_labels, y_train_pred_binary_other)\n",
    "    precision_scores[idx] = precision_score(data_labels, y_train_pred_binary_other)\n",
    "    recall_scores[idx] = recall_score(data_labels, y_train_pred_binary_other)\n",
    "    roc_scores[idx] = roc_auc_score(data_labels, y_train_pred_binary_other)\n",
    "\n",
    "    full_pipeline_with_predictor = Pipeline([\n",
    "        (\"preparation\", full_pipeline),\n",
    "        (\"cls\", other_cls),\n",
    "    ])\n",
    "    \n",
    "    # Predict using test data.\n",
    "    y_train_pred_binary_split = full_pipeline_with_predictor.predict(test_data)\n",
    "\n",
    "    # Record test data scores.\n",
    "    split_accuracy_scores[idx] = accuracy_score(test_labels, y_train_pred_binary_split)\n",
    "    split_f1_scores[idx] = f1_score(test_labels, y_train_pred_binary_split)\n",
    "    split_precision_scores[idx] = precision_score(test_labels, y_train_pred_binary_split)\n",
    "    split_recall_scores[idx] = recall_score(test_labels, y_train_pred_binary_split)\n",
    "    split_roc_scores[idx] = roc_auc_score(test_labels, y_train_pred_binary_split)\n",
    "\n",
    "# Results\n",
    "\n",
    "# Cross validated DataFrame.\n",
    "other_df = pd.DataFrame(columns=['Name', 'Accuracy', 'F1', 'Precision', 'Recall', 'ROC', 'Average'])\n",
    "\n",
    "# Test set DataFrame.\n",
    "other_df_split = pd.DataFrame(columns=['Name', 'Accuracy', 'F1', 'Precision', 'Recall', 'ROC', 'Average'])\n",
    "\n",
    "# Record values into DataFrames.\n",
    "for i, o in enumerate(other_cls_list):\n",
    "    other_df.loc[i] = [\n",
    "        '{}'.format(o.__class__.__name__),\n",
    "        accuracy_scores[i],\n",
    "        f1_scores[i],\n",
    "        precision_scores[i],\n",
    "        recall_scores[i],\n",
    "        roc_scores[i],\n",
    "        np.average([\n",
    "            accuracy_scores[i],\n",
    "            f1_scores[i],\n",
    "            precision_scores[i],\n",
    "            recall_scores[i],\n",
    "            roc_scores[i],\n",
    "        ])\n",
    "    ]\n",
    "\n",
    "    other_df_split.loc[i] = [\n",
    "        '{}'.format(o.__class__.__name__),\n",
    "        split_accuracy_scores[i],\n",
    "        split_f1_scores[i],\n",
    "        split_precision_scores[i],\n",
    "        split_recall_scores[i],\n",
    "        split_roc_scores[i],\n",
    "        np.average([\n",
    "            split_accuracy_scores[i],\n",
    "            split_f1_scores[i],\n",
    "            split_precision_scores[i],\n",
    "            split_recall_scores[i],\n",
    "            split_roc_scores[i],\n",
    "        ])\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Cross Validated scores.\n",
    "\n",
    "other_df.sort_values('Average', ascending=False).head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize test set scores.\n",
    "\n",
    "other_df_split.sort_values('Average', ascending=False).head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to file for averaging.\n",
    "\n",
    "other_df.to_json(os.path.join('datasets', 'base_{}_evaluation_result_cv.json'.format(BASE_NUM)))\n",
    "other_df_split.to_json(os.path.join('datasets', 'base_{}_evaluation_result_split.json'.format(BASE_NUM)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
